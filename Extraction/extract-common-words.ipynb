{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/a-guide-to-encoding-text-in-python-ef783e50f09e\n",
    "# https://medium.com/@cmukesh8688/tf-idf-vectorizer-scikit-learn-dbc0244a911a\n",
    "# https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the report (in .txt format)\n",
    "fileObject = open(\"ar4_wg3_full_report-1.txt\", \"r\")\n",
    "data1 = fileObject.read()\n",
    "\n",
    "fileObject = open(\"IPCC_AR6_WGIII_FinalDraft_FullReport.txt\", \"r\")\n",
    "data2 = fileObject.read()\n",
    "\n",
    "fileObject = open(\"ipcc_wg3_ar5_full.txt\", \"r\")\n",
    "data3 = fileObject.read()\n",
    "\n",
    "fileObject = open(\"WGIII_TAR_full_report.txt\", \"r\")\n",
    "data4 = fileObject.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the documents\n",
    "corpus = [data1, data2, data3, data4]\n",
    "\n",
    "# implement tfidf\n",
    "tfidf = TfidfVectorizer(analyzer='word', stop_words= 'english', ngram_range=(1,2))\n",
    "tfidf.fit(corpus)\n",
    "X = tfidf.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['energy', 'emissions', 'al', 'climate', 'et', 'et al', '10', 'change',\n",
      "       'mitigation', 'carbon'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# convert to dataframe\n",
    "X_df = pd.DataFrame(X.toarray(), columns=sorted(tfidf.vocabulary_))\n",
    "word_frequency_df = X_df.T\n",
    "avg_df = word_frequency_df.sum(axis=1, numeric_only=True) / 4\n",
    "avg_df = avg_df.sort_values(ascending=False)\n",
    "print(avg_df.index[:10])\n",
    "# yet to do: delete numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['energy', 'emissions', 'climate', 'change', 'mitigation', 'carbon', 'doi', 'policy', 'countries', 'global', 'development', 'use', 'climate change', 'costs', 'co2', 'economic', 'doi 10', 'policies', 'cost', 'ghg', 'environmental', 'potential', 'scenarios', 'chapter', 'technology', 'international', 'gas', 'emission', 'efficiency', 'technologies', 'new', 'sector', 'high', 'fuel', 'low', 'national', 'benefits', 'reduction', 'land', 'world', 'sustainable', 'studies', 'ipcc', 'based', 'options', 'non', 'systems', 'developing', 'production', 'total', 'transport', 'impacts', 'market', 'different', 'assessment', 'report', 'power', 'future', 'social', 'management', 'research', 'ghg emissions', 'term', 'analysis', 'section', 'electricity', 'used', 'greenhouse', 'reduce', 'effects', 'measures', 'available', 'figure', 'industry', 'demand', 'issn', 'technological', 'growth', 'reductions', 'org', 'level', 'increase', 'models', 'https doi', 'including', 'range', 'long', 'oecd', 'university', 'public', 'waste', 'government', 'iea', 'environment', 'large', 'air', 'fossil', 'trade', 'buildings', 'forest', 'agreement', 'time', 'example', 'levels', 'consumption', 'supply', 'developing countries', 'table', 'https', 'baseline', 'annex', 'include', 'energy efficiency', 'http', 'important', 'urban', 'impact', 'sectors', 'scenario', 'usa', 'lower', 'greenhouse gas', 'adaptation', 'regional', 'related', 'united', 'economics', 'model', 'higher', 'changes', 'journal', 'co2 emissions', 'net', 'www', 'sustainable development', 'biomass', 'kyoto', 'industrial', 'case', 'literature', 'evidence', 'resources', 'issues', 'estimates', 'tax', 'using', 'technical', 'investment', 'data', 'fuels', 'price', 'renewable', 'economy', 'developed', 'information', 'total pages', 'specific']\n"
     ]
    }
   ],
   "source": [
    "# List of the 200 most frequent owrds\n",
    "words_list = list(avg_df.index[:200])\n",
    "\n",
    "# Some filters\n",
    "for word in words_list:\n",
    "    # Remove numbers\n",
    "    if word.isnumeric():\n",
    "        words_list.remove(word)\n",
    "    # Remove words of size 2 or less\n",
    "    elif len(word.split()[0]) <= 2:\n",
    "        words_list.remove(word)\n",
    "\n",
    "for word in words_list:\n",
    "    # Remove numbers\n",
    "    if word.isnumeric():\n",
    "        words_list.remove(word)\n",
    "    # Remove words of size 2 or less\n",
    "    elif len(word.split()[0]) <= 2:\n",
    "        words_list.remove(word)\n",
    "    \n",
    "print(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"most-frequent-monobigrams-list\", \"w\") as fp:\n",
    "    json.dump(words_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('your_file.txt', 'w') as f:\n",
    "    for item in words_list:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get code wikidata code from word\n",
    "# iterate through the words to find relational links of first or second order\n",
    "# stock it in a n^2 matrix"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e49c4e175cb16aba6a0358835ea6ba1fe142c983ecf797a4e898bb7491d387d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
